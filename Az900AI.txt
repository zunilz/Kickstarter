ML
  -ability to develop algorithm by itself
  -Unsupervised learning and Supervised learning

ML Model
  -is a program that can be used to recognize a pattern in data
  -can be used to predict fututre behaviours
  -can be used to categorize things
  -can be used to recognize people, objects and landmarks
  -can be used to understands speech and text model
  -you train a model
  -you evaluate a model using test data to measure how accurate is it
  -at the end deploy the model

AI Workloads
  -1. Prediction and Demand Forecasting
  -2. Anamoly Detection
  -3. Computer Vision
  -4. NLP
  -5. Conversational AI
  
Guiding Principles of AI
  -Fairness
  -Reliability and Safety
  -Privacy and Security
  -Inclusiveness
  -Transparency
  -Accountability

Machine Learning on Azure
  -Algorithms
    -Regression - finding the relationship between variables
  -Classification
    -Binary classification
    -Multi-class classification
  -Clustering
    -type of unsupervised learning
    -finds groups of related things among data
  -Feature and Labels
    -Feature is an input variable
    -When we are looking to predict a filed, it is called label
  -Training the Model
    -Split the training and validation datasets randomnly
  -Evaluate results - Regression
    -use the validation dataset to test the model
    -Mean Square Error
      -large differences are much worse than small differences
  -Evaluate results - Classification
    -result is to give a prediction score that subject is pasrt of the group
    -False Positives vs False Negatives

  Confusion Matrix
    -Classification Model
      -Actual Values and Predicted values
      -TP, FP, FN, TN
      -          Positive   Negative
       Positive    TP          FP
       Negative    FN          TN
      -Reciever Operating Characteristic (ROC) Curve
      -Area under the Curve (AUC)

No Code ML
  -AutoML is a tool for this
    -Drag dataset onto designer
    -Visualize data, Exclude cloumns if not required
    -Clean rows with missing data
    -Drag training models onto the canvas
    -Once training model as all verified,Training pipeline can be converted into inference pipeline
  -Azure ML designer
    -need to pick the data model unlike auto ML

Computer Vision Workloads
  -Common types of computer vision
    -image classification
    -object detection
    -OCR
    -facial detection and recognition
  -Computer Vision service
    -Azure face service
    -Form recognizer service
  -Custom vision service

NLP
  -Usecases
  -Sentiment analysis
    -positive, negative and neutral
  -Language modelling
  -Speech recognition and synthesis
  -Translation
  -Text Analytics Service
  -Text translation Service
  
Conversational AI
  -QnA maker service
    -to build chatbot
  -Azure Bot Service

Test content:

When categorizing an image, the computer vision service supports two specialized domain models: celebrities and landmarks. Image types is an additional capability of the computer vision service, allowing it to detect the type of image, such as a clip art image or a line drawing. Both people_ and people_group are supported categories when performing image classification.

OCR can extract printed or handwritten text from images. In this case, it can be used to extract text from scanned medical records to produce a digital archive from paper-based documents. 
Identifying wildlife in an image is an example of a computer vision solution that uses object detection and is not suitable for OCR. 
Identifying a user requesting access to a laptop is done by taking images from the laptop’s webcam and using facial detection and recognition to identify the user requesting access. 
Translating speech to text is an example of using speech translation and uses the Speech service as part of Azure Cognitive Services.

Object detection can be used to track livestock animals, such as cows, to support their safety and welfare. For example, a farmer can track whether a particular animal has not been mobile. 
Sentiment analysis is used to return a numeric value based on the analysis of a text. 
Employee access to a secure building can be achieved by using facial recognition. 
Extracting text from manuscripts is an example of a computer vision solution that uses optical character recognition (OCR).
Image classification is part of computer vision and can be used to evaluate images from an X-ray machine to quickly classify specific bone fracture types. This helps improve diagnosis and treatment plans. An image classification model is trained to facilitate the categorizing of the bone fractures. 
Object detection is used to return identified objects in an image, such as a cat, person, or chair. 
Conversational AI is used to create intelligent bots that can interact with people by using natural language. 
Facial detection is used to detect the location of human faces in an image.
The computer vision service eliminates the need for choosing, training, and evaluating a model by providing pre-trained models. To use computer vision, you must create an Azure resource. The use of computer vision involves inferencing.
Detecting objects identifies common objects and, for each, returns bounding box coordinates. Image categorization assigns a category to an image, but it does not return bounding box coordinates. Tagging involves associating an image with metadata that summarizes the attributes of the image, but it does not return bounding box coordinates. OCR detects printed and handwritten text in images, but it does not return bounding box coordinates.

The invoice model extracts key information from sales invoices and is suitable for extracting information from sales account documents. 
The ID document model is optimized to analyze and extract key information from US driver’s licenses and international passport biographical pages. 
The business card model, receipt model, and language model are not suitable to extract information from passports or sales account documents.
Face attributes are a set of features that can be detected by the Face Detect API. Attributes such as accessories (glasses, mask, headwear etc.) can be detected. 
Face rectangle, face ID, and face landmarks do not allow you to determine whether a person is wearing glasses or headwear.
Face identification in the Face service can address one-to-many matching of one face in an image to a set of faces in a secure repository. Face verification has the capability for one-to-one matching of a face in an image to a single face from a secure repository or a photo to verify whether they are the same individual. Face attributes, the find similar faces operation, and Custom Vision do not verify the identity of a face.
Multiple linear regression models a relationship between two or more features and a single label, which matches the scenario in this item. 
Linear regression uses a single feature. Logistic regression is a type of classification model, which returns either a Boolean value or a categorical decision. 
Hierarchical clustering groups data points that have similar characteristics.
Predicting rainfall is an example of regression machine learning, as it will predict a numeric value for future rainfall by using historical time-series rainfall data based on factors, such as seasons. 
Regression is a machine learning scenario that is used to predict numeric values. In this example, regression will be able to predict future energy consumption based on analyzing historical time-series energy data based on factors, such as seasonal weather and holiday periods. Multiclass classification is used to predict categories of data. Clustering analyzes unlabeled data to find similarities present in the data. Classification is used to predict categories of data.
Multiple linear regression models the relationship between several features and a single label. The features must be independent of each other, otherwise, the model's predictions will be misleading.
Regression is an example of supervised machine learning due to the use of historical data with known label values to train a model. Regression does not rely on randomly generated data for training. 

Clustering is a machine learning type that analyzes unlabeled data to find similarities in the data. 
Featurization is not a machine learning type, but a collection of techniques, such as feature engineering, data-scaling, and normalization. 
Classification is used to predict categories of data.
The validation dataset is a sample of data held back from a training dataset. It is then used to evaluate the performance of the trained model. Cleaning missing data is used to detect missing values and perform operations to fix the data or create new values. Feature engineering is part of preparing the dataset and related data transformation processes. Summarizing the data is used to provide summary statistics, such as the mean or count of distinct values in a column.
You can deploy the best performing model for client applications to use over the internet by using an endpoint. Compute clusters are used to train the model and are created directly after you create a Machine Learning workspace. Before you can test the model’s endpoint, you must deploy it first to an endpoint. Automated ML performs the validation automatically, so you do not need to split the dataset.
K-means clustering is an unsupervised machine learning algorithm component used for training clustering models. You can use unlabeled data with this algorithm. Linear regression and classification are supervised machine learning algorithm components. You need labeled data to use these algorithms. Normalize Data is not a machine learning algorithm module.
Semantic segmentation provides the ability to classify individual pixels in an image depending on the object that they represent. The other answer choices also process images, but their outcomes are different.


Modern image classification solutions are based on deep learning techniques. Anomaly detection analyzes data collected over time to identify errors or unusual changes. Both linear regression and multiple linear regression use training and validating predictions to predict numeric values, so they are not part of image classification solutions.

Each phrase returned by an image description task of the computer vision service includes the confidence score. An endpoint and a key must be provided to access the computer vision service. Bounding box coordinates are returned by services such as object detection, but not image description.



Classification is used to predict categories of data. It can predict which category or class an item of data belongs to. In this example, a machine learning model trained by using classification with labeled data can be used to determine the type of bone fracture in a new scan that is not labeled already. Featurization is not a machine learning type. 
Regression is used to predict numeric values. 
Clustering analyzes unlabeled data to find similarities in the data.

In a regression machine learning algorithm, features are used to generate predictions for the label, which is compared to the actual label value. There is no direct comparison of features or labels between the validation and training datasets.
Multiple linear regression models the relationship between several features and a single label. The features must be independent of each other, otherwise, the model's predictions will be misleading.
In a regression machine learning algorithm, a validation set contains known feature and label values.
The price of the house is the label you are attempting to predict through the machine learning model. This is typically done by using a regression model. Floor space size, number of bedrooms, and age of the house are all input variables for the model to help predict the house price label.

Weather temperature and weekday or weekend are features that provide a weather temperature for a given day and a value based on whether the day is on a weekend or weekday. These are input variables for the model to help predict the labels for e-scooter battery levels, number of hires, and distance traveled. E-scooter battery levels, number of hires, and distance traveled are numeric labels you are attempting to predict through the machine learning model.
Splitting data into training and validation datasets leaves you with two datasets, the first and largest of which is the training dataset you use to train the model. The second, smaller dataset is the held back data and is called the validation dataset, as it is used to evaluate the trained model. If normalizing or summarizing the data is required, it will be carried out as part of data transformation. Cleaning missing data is part of preparing the data and the data transformation processes.
A dataset is required to create an automated machine learning (automated ML) run. A workspace must be created before you can access Machine Learning studio. An Azure container instance and an AKS cluster can be created as a deployment target, after training of a model is complete.
Before you can start training a machine learning model, you must first create a pipeline in the Machine Learning designer. This is followed by adding a dataset, adding training modules, and eventually deploying a service.
Time-series forecasting, regression, and classification are supervised machine learning models. Automated ML learning can predict categories or classes by using a classification algorithm, as well as numeric values as part of the regression algorithm, and at a future point in time by using time-series data. Inference pipeline is not a machine learning model. Clustering is unsupervised machine learning and automated ML only works with supervised learning algorithms.
Normalize Data is a data transformation module that is used to change the values of numeric columns in a dataset to a common scale, without distorting differences in the range of values. The Clean Missing Data module is part of preparing the data and data transformation process. Select Columns in Dataset is a data transformation component that is used to choose a subset of columns of interest from a dataset. The train clustering model is not a part of data transformation. The evaluate model is a component used to measure the accuracy of training models.
Linear regression is a machine learning algorithm module used for training regression models. The Clean Missing Data module is part of preparing the data and data transformation process. Select Columns in Dataset is a data transformation component that is used to choose a subset of columns of interest from a dataset. Evaluate model is a component used to measure the accuracy of trained models.
Vectorization captures semantic relationships between words by assigning them to locations in n-dimensional space. Lemmatization, also known as stemming, normalizes words before counting them. Frequency analysis counts how often a word appears in a text. N-grams extend frequency analysis to include multi-term phrases.
Tokenization is part of speech synthesis that involves breaking text into individual words such that each word can be assigned phonetic sounds. Transcribing is part of speech recognition, which involves converting speech into a text representation. Key phrase extraction is part of language processing, not speech synthesis. Lemmatization, also known as stemming, is part of language processing, not speech synthesis.
The Universal Language Model used by the speech-to-text API is optimized for conversational and dictation scenarios. The acoustic, language, and pronunciation scenarios require developing your own model.
Azure Cognitive Services provides direct access to both Translator and Speech services through a single endpoint and authentication key. Language service can be used to access the Language service, but not the Translator and Speech services. The Machine Learning service is used to design, implement, and deploy Machine Learning models. Azure Bot Service provides a framework for developing, publishing, and managing bots in Azure.
Speech recognition uses audio data to analyze speech and determine recognizable patterns that can be mapped to distinct user voices. Speech synthesis is concerned with vocalizing data, usually by converting text to speech. Speech translation is concerned with multilanguage translation of speech. Language identification is used to identify languages spoken in audio when compared against a list of supported languages.
The two main schema components of a Language Understanding app model are entities and intents. Utterances play an important role in training the model, but they are not part of its schema. Entity Linking is part of the entity recognition service, which returns links to external websites to disambiguate terms (entities) identified in a text.
Utterances are used to train and test a Language Understanding app model. Entities and intents are core components of a Language Understanding app model, but they are not used for testing the model. Entity Linking is part of the entity recognition service, which returns links to external websites to disambiguate terms (entities) identified in a text.
The Language Studio provides the easiest way to create a knowledge base for Azure Bot Service. While it is possible to create a knowledge base by using the features of the Machine Learning studio, this is not the simplest method to accomplish the given objective. The Azure portal and Azure Cloud Shell allow for creating the Language resource, but will not create a knowledge base for Azure Bot Service.
Structure and unstructured DOC files and PDF files can be imported to generate a knowledge base for use with Azure Bot Service. ZIP files must first be extracted before they can be imported. MP4 files and CSV files are not supported to generate question-and-answer pairs for use with Azure Bot Service.
A webpage or an existing document, such as a text file containing question and answer pairs, can be used to generate a knowledge base. You can also manually enter the knowledge base question-and-answer pairs. You cannot directly use an image or an audio file to import a knowledge base.







Removing stop words is the first step in the statistical analysis of terms used in a text in the context of NLP. Counting the occurrences of each word takes place after stop words are removed. Creating a vectorized model is not part of statistical analysis. It is used to capture the sematic relationship between words. Encoding words as numeric features is not part of statistical analysis. It is frequently used in sentiment analysis.
Sentiment analysis provides sentiment labels, such as negative, neutral, and positive, based on a confidence score from text analysis. This makes it suitable for understanding user sentiment for product reviews. The named entity recognition, key phrase extraction, and language detection features cannot perform sentiment analysis for product reviews.
Key phrase extraction is used to extract key phrases to identify the main concepts in a text. It enables a company to identify the main talking points from the support question data and allows them to identify common issues. Named entity recognition can identify and categorize entities in unstructured text, such as people, places, organizations, and quantities. The Speech service, Conversational Language Understanding, and Azure Bot Service are not designed for identifying key phrases or entities.
Language Name, ISO 6391 Code, and Score are three values returned by the Language service of natural language processing (NLP) in Azure. Bounding box coordinates are returned by the computer vision services in Azure. Wikipedia URL is one of potential values returned by entity linking of entity recognition.
The Universal Language Model used by the speech-to-text API is optimized for conversational and dictation scenarios. The acoustic, language, and pronunciation scenarios require developing your own model.
Azure Cognitive Services provides direct access to both Translator and Speech services through a single endpoint and authentication key. Language service can be used to access the Language service, but not the Translator and Speech services. The Machine Learning service is used to design, implement, and deploy Machine Learning models. Azure Bot Service provides a framework for developing, publishing, and managing bots in Azure.
Entity Linking, PII detection, and sentiment analysis are all elements of the Azure Cognitive Service for Language. Anomaly detection monitors data over time to detect anomalies by using machine learning. Content Moderator is an Azure Cognitive Services service that is used to check text, image, and video content for material that is potentially offensive.
Language identification, speaker recognition, and voice assistants are all elements of the Speech service. Text translation and document translation are part of the Translator service.
Entity Linking identifies and disambiguates the identity of entities found in a text. Key phrase extraction is not used to extract entities and is used instead to extract key phrases to identify the main concepts in a text. Named entity recognition cannot provide a link for each entity to view further information. Text translation is part of the Translator service.
Speech recognition uses audio data to analyze speech and determine recognizable patterns that can be mapped to distinct user voices. Speech synthesis is concerned with vocalizing data, usually by converting text to speech. Speech translation is concerned with multilanguage translation of speech. Language identification is used to identify languages spoken in audio when compared against a list of supported languages.
The two main components of a conversational AI solution are a bot service and a knowledge base. Entity Linking is part of the entity recognition service, which returns links to external websites to disambiguate terms (entities) identified in a text. Key phrase extraction evaluates the text of a document and identifies its main talking points, but it is not one of two main components of a conversational AI solution.
The Language service enables you to create a knowledge base of question-and-answer pairs that can be phrased by users in multiple ways with the same semantic meaning. A knowledge base is a required data source to enable the creation of a conversational AI solution. Azure Bot Service provides an interface through which users can interact with the knowledge base by using one or more channels. Sentiment analysis, speech synthesis, and Content Moderator are not required features.
A bot can be used to respond to new student queries or to respond to questions via communication channels, such as email. Azure Bot Service does not have the capability to translate text. The detection of anomalies in financial transactions is a workload suited to the Anomaly Detector service. The classification of image vehicle types is a computer vision workload and is not suited to a web chatbot.
Anomaly detection analyzes data collected over time to identify errors or unusual changes. This allows for predicting impending failures. Other answer choices represent AI capabilities unrelated to the detecting impending failures.
Translating text between different languages from product reviews is an NLP workload that uses the Translator service and is part of Azure Cognitive Services. It can provide text translation of supported languages in real time. Performing sentiment analysis on social media data is an NLP that uses the sentiment analysis feature of the Azure Cognitive Service for Language. It can provide sentiment labels, such as negative, neutral, and positive for text-based sentences and documents.
Data mining workloads primarily focus on the searching and indexing of data. The computer vision service can be used to extract information from images, but it is not a search and indexing solution. Conversational AI is part of natural language processing (NLP) and facilitates the creation of chatbots. Anomaly detection is not used for searching and indexing data. This is used to detect outliers in data, such as unusual credit card activity for the detection of fraud.
OCR and Spatial Analysis are part of the computer vision service. Sentiment analysis, entity recognition, and key phrase extraction are not part of the computer vision service.
Fairness involves evaluating and mitigating the bias introduced by the features of a model. 
Privacy is meant to ensure that privacy provisions are included in AI solutions. Transparency provides clarity regarding the purpose of AI solutions, the way they work, as well as their limitations. 
Accountability is focused on ensuring that AI solutions meet ethical and legal standards that are clearly defined.
The accountability principle states that AI systems are designed to meet any ethical and legal standards that are applicable. The system must be designed to ensure that privacy of the healthcare data is of the highest importance, including anonymizing data where applicable. The fairness principle is applied to AI systems to ensure that users of the systems are treated fairly. The inclusiveness principle states that AI systems must empower people in a positive and engaging way.


---------------------------------------------------------------------------------------------------

1.	Vectorization captures semantic relationships between words by assigning them to locations in n-dimensional space. Lemmatization, also known as stemming, normalizes words before counting them. Frequency analysis counts how often a word appears in a text. N-grams extend frequency analysis to include multi-term phrases
2.	NaN, or not a number, designates an unknown confidence score. Unknown is a value with which the NaN confidence score is associated. The score values range between 0 and 1, with 0 designating the lowest confidence score and 1 designating the highest confidence score.
3.	The Speech service can be used to generate spoken audio from a text source for text-to-speech translation. The Translator service directly supports text-to-text translation in more than 60 languages. Key phrase extraction, Conversational Language Understanding, and language detection are not used for language translation for text-to-text and speech-to-text translation.
4.	Language Name, ISO 6391 Code, and Score are three values returned by the Language service of natural language processing (NLP) in Azure. Bounding box coordinates are returned by the computer vision services in Azure. Wikipedia URL is one of potential values returned by entity linking of entity recognition.
5.	Azure Cognitive Services provides direct access to both Translator and Speech services through a single endpoint and authentication key. Language service can be used to access the Language service, but not the Translator and Speech services. The Machine Learning service is used to design, implement, and deploy Machine Learning models. Azure Bot Service provides a framework for developing, publishing, and managing bots in Azure.
6.	Entity Linking, PII detection, and sentiment analysis are all elements of the Azure Cognitive Service for Language. Anomaly detection monitors data over time to detect anomalies by using machine learning. Content Moderator is an Azure Cognitive Services service that is used to check text, image, and video content for material that is potentially offensive.
7.	Language identification, speaker recognition, and voice assistants are all elements of the Speech service. Text translation and document translation are part of the Translator service.
8.	Model training with a dictionary can be used with Custom Translator when you do not have enough parallel sentences to meet the 10,000 minimum requirements. The resulting model will typically complete training much faster than with full training and will use the baseline models for translation along with the dictionaries you have added.
9.	Entity Linking identifies and disambiguates the identity of entities found in a text. Key phrase extraction is not used to extract entities and is used instead to extract key phrases to identify the main concepts in a text. Named entity recognition cannot provide a link for each entity to view further information. Text translation is part of the Translator service.
10.	Utterances are used to train and test a Language Understanding app model. Entities and intents are core components of a Language Understanding app model, but they are not used for testing the model. Entity Linking is part of the entity recognition service, which returns links to external websites to disambiguate terms (entities) identified in a text.
11.	The Language Studio provides the easiest way to create a knowledge base for Azure Bot Service. While it is possible to create a knowledge base by using the features of the Machine Learning studio, this is not the simplest method to accomplish the given objective. The Azure portal and Azure Cloud Shell allow for creating the Language resource, but will not create a knowledge base for Azure Bot Service.
12.	The Language service enables you to create a knowledge base of question-and-answer pairs that can be phrased by users in multiple ways with the same semantic meaning. A knowledge base is a required data source to enable the creation of a conversational AI solution. Azure Bot Service provides an interface through which users can interact with the knowledge base by using one or more channels. Sentiment analysis, speech synthesis, and Content Moderator are not required features.
13.	Structure and unstructured DOC files and PDF files can be imported to generate a knowledge base for use with Azure Bot Service. ZIP files must first be extracted before they can be imported. MP4 files and CSV files are not supported to generate question-and-answer pairs for use with Azure Bot Service.
14.	A webpage or an existing document, such as a text file containing question and answer pairs, can be used to generate a knowledge base. You can also manually enter the knowledge base question-and-answer pairs. You cannot directly use an image or an audio file to import a knowledge base.
15.	Object detection provides the ability to generate bounding boxes identifying the locations of different types of vehicles in an image. The other answer choices also process images, but their outcomes are different.
16.	Semantic segmentation provides the ability to classify individual pixels in an image depending on the object that they represent. The other answer choices also process images, but their outcomes are different.
17.	Anomaly detection analyzes data collected over time to identify errors or unexpected changes. This allows for identifying unusual credit card transactions that might indicate a criminal activity. Form Recognizer and semantic segmentation are part of computer vision, so they do not play any role in credit card transaction processing. Bot services are part of natural language processing (NLP), without any significant role in credit card transaction processing.
18.	Knowledge mining is an artificial intelligence (AI) workload that has the purpose of making large amounts of data searchable. While other workloads leverage indexing for faster access to large amounts of data, this is not their primary purpose.
19.	Extracting key phrases from text to identify the main terms is an NLP workload. Predicting whether customers are likely to buy a product based on previous purchases requires the development of a machine learning model. Monitoring for sudden increases in quantity of failed sign-in attempts is an anomaly detection workload. Identifying objects in landscape images is a computer vision workload.
20.	Data mining workloads primarily focus on the searching and indexing of data. The computer vision service can be used to extract information from images, but it is not a search and indexing solution. Conversational AI is part of natural language processing (NLP) and facilitates the creation of chatbots. Anomaly detection is not used for searching and indexing data. This is used to detect outliers in data, such as unusual credit card activity for the detection of fraud.
21.	OCR and Spatial Analysis are part of the computer vision service. Sentiment analysis, entity recognition, and key phrase extraction are not part of the computer vision service.
22.	Detecting credit card fraud is an anomaly detection workload that uses the Anomaly Detector service to detect abnormalities in time-series data. For example, it can compare previous bank transactions to new transactions and detect abnormalities, such as an unusually large credit card purchase.
23.	The transparency principle states that AI systems must be designed in such a way that users are made fully aware of the purpose of the systems, how they work, and which limitations can be expected during use. The inclusiveness principle states that AI systems must empower people in a positive and engaging way. Fairness is applied to AI systems to ensure that users of the systems are treated fairly. The privacy and security principle is applied to the design of AI systems to ensure that the systems are secure and to respect user privacy.
24.	The AI system must be designed to ensure that biased decision making is avoided and not based on factors such as ethnicity and gender. The system will consider salary, payment history, and credit utilization. These are standard metrics.
25.	The reliability and safety principle is of paramount importance here as it requires an AI system to work alongside people in a physical environment by using AI controlled machinery. The system must function safely, while ensuring no harm will come to human life.
26.	Multiple linear regression models a relationship between two or more features and a single label, which matches the scenario in this item. Linear regression uses a single feature. Logistic regression is a type of classification model, which returns either a Boolean value or a categorical decision. Hierarchical clustering groups data points that have similar characteristics.
27.	The regression algorithms are used to predict numeric values. Clustering algorithms groups data points that have similar characteristics. Classification algorithms are used to predict the category to which an input value belongs. Unsupervised learning is a category of learning algorithms that includes clustering, but not regression or classification.
28.	Clustering algorithms group data points that have similar characteristics. Regression algorithms are used to predict numeric values. Classification algorithms are used to predict a predefined category to which an input value belongs. Supervised learning is a category of learning algorithms that includes regression and classification, but not clustering.
29.	Classification algorithms are used to predict a predefined category to which an input value belongs. Regression algorithms are used to predict numeric values. Clustering algorithms group data points that have similar characteristics. Unsupervised learning is a category of learning algorithms that includes clustering, but not regression or classification.
30.	Classification is used to predict categories of data. It can predict which category or class an item of data belongs to. In this example, a machine learning model trained by using classification with labeled data can be used to determine the type of bone fracture in a new scan that is not labeled already. Featurization is not a machine learning type. Regression is used to predict numeric values. Clustering analyzes unlabeled data to find similarities in the data.
31.	In a regression machine learning algorithm, features are used to generate predictions for the label, which is compared to the actual label value. There is no direct comparison of features or labels between the validation and training datasets.
32.	Multiple linear regression models the relationship between several features and a single label. The features must be independent of each other, otherwise, the model's predictions will be misleading.
33.	The price of the house is the label you are attempting to predict through the machine learning model. This is typically done by using a regression model. Floor space size, number of bedrooms, and age of the house are all input variables for the model to help predict the house price label.
34.	Weather temperature and weekday or weekend are features that provide a weather temperature for a given day and a value based on whether the day is on a weekend or weekday. These are input variables for the model to help predict the labels for e-scooter battery levels, number of hires, and distance traveled. E-scooter battery levels, number of hires, and distance traveled are numeric labels you are attempting to predict through the machine learning model.
35.	Weather temperature and weekday or weekend are features that provide a weather temperature for a given day and a value based on whether the day is on a weekend or weekday. These are input variables for the model to help predict the labels for e-scooter battery levels, number of hires, and distance traveled. E-scooter battery levels, number of hires, and distance traveled are numeric labels you are attempting to predict through the machine learning model.
36.	A dataset is required to create an automated machine learning (automated ML) run. A workspace must be created before you can access Machine Learning studio. An Azure container instance and an AKS cluster can be created as a deployment target, after training of a model is complete.
37.	Before you can start training a machine learning model, you must first create a pipeline in the Machine Learning designer. This is followed by adding a dataset, adding training modules, and eventually deploying a service.
38.	You can deploy the best performing model for client applications to use over the internet by using an endpoint. Compute clusters are used to train the model and are created directly after you create a Machine Learning workspace. Before you can test the model’s endpoint, you must deploy it first to an endpoint. Automated ML performs the validation automatically, so you do not need to split the dataset.
39.	Time-series forecasting, regression, and classification are supervised machine learning models. Automated ML learning can predict categories or classes by using a classification algorithm, as well as numeric values as part of the regression algorithm, and at a future point in time by using time-series data. Inference pipeline is not a machine learning model. Clustering is unsupervised machine learning and automated ML only works with supervised learning algorithms
40.	Linear regression is a machine learning algorithm module used for training regression models. The Clean Missing Data module is part of preparing the data and data transformation process. Select Columns in Dataset is a data transformation component that is used to choose a subset of columns of interest from a dataset. Evaluate model is a component used to measure the accuracy of trained models.
41.	Modern image classification solutions are based on deep learning techniques. Anomaly detection analyzes data collected over time to identify errors or unusual changes. Both linear regression and multiple linear regression use training and validating predictions to predict numeric values, so they are not part of image classification solutions.
42.	OCR provides the ability to detect and read text in images. NLP is an area of AI that deals with identifying the meaning of a written or spoken language, but not detecting or reading text in images. Image classification classifies images based on their contents. Semantic segmentation provides the ability to classify individual pixels in an image.
43.	Facial detection provides the ability to detect and analyze human faces in an image, including identifying a person's age based on a photograph. Image classification classifies images based on their contents. Object detection provides the ability to generate bounding boxes identifying the locations of different types of vehicles in an image. Semantic segmentation provides the ability to classify individual pixels in an image.
44.	Object detection can be used to track livestock animals, such as cows, to support their safety and welfare. For example, a farmer can track whether a particular animal has not been mobile. Sentiment analysis is used to return a numeric value based on the analysis of a text. Employee access to a secure building can be achieved by using facial recognition. Extracting text from manuscripts is an example of a computer vision solution that uses optical character recognition (OCR).
45.	Image classification is part of computer vision and can be used to evaluate images from an X-ray machine to quickly classify specific bone fracture types. This helps improve diagnosis and treatment plans. An image classification model is trained to facilitate the categorizing of the bone fractures. Object detection is used to return identified objects in an image, such as a cat, person, or chair. Conversational AI is used to create intelligent bots that can interact with people by using natural language. Facial detection is used to detect the location of human faces in an image.
46.	OCR is used to extract text and handwriting from images. In this case, it can be used to extract signatures for attendance purposes. Face detection can detect and verify human faces, not text, from images. Object detection can detect multiple objects in an image by using bounding box coordinates. It is not used to extract handwritten text. Image classification is the part of computer vision that is concerned with the primary contents of an image.
47.	The invoice model extracts key information from sales invoices and is suitable for extracting information from sales account documents. The ID document model is optimized to analyze and extract key information from US driver’s licenses and international passport biographical pages. The business card model, receipt model, and language model are not suitable to extract information from passports or sales account documents.
48.	Face attributes are a set of features that can be detected by the Face Detect API. Attributes such as accessories (glasses, mask, headwear etc.) can be detected. Face rectangle, face ID, and face landmarks do not allow you to determine whether a person is wearing glasses or headwear.
49.	Custom Vision is an image recognition service that allows you to build and deploy your own image models. The computer vision service, Face service, and Language service do not provide the capability to train your own image model.
50.	Object detection provides the ability to generate bounding boxes identifying the locations of different types of vehicles in an image. The other answer choices also process images, but their outcomes are different
51.	Bot services provide a platform for conversational artificial intelligence (AI), which designates the ability of software agents to participate in a conversation. Translator is part of Natural language processing (NLP), but it does not serve as a platform for conversational AI. Semantic segmentation deals with image processing. Form Recognizer extracts information from scanned forms and invoices.
52.	Anomaly detection analyzes data collected over time to identify errors or unexpected changes. This allows for identifying unusual credit card transactions that might indicate a criminal activity. Form Recognizer and semantic segmentation are part of computer vision, so they do not play any role in credit card transaction processing. Bot services are part of natural language processing (NLP), without any significant role in credit card transaction processing.
53.	Data mining workloads primarily focus on the searching and indexing of data. The computer vision service can be used to extract information from images, but it is not a search and indexing solution. Conversational AI is part of natural language processing (NLP) and facilitates the creation of chatbots. Anomaly detection is not used for searching and indexing data. This is used to detect outliers in data, such as unusual credit card activity for the detection of fraud.
54.	Data mining workloads primarily focus on the searching and indexing of data. The computer vision service can be used to extract information from images, but it is not a search and indexing solution. Conversational AI is part of natural language processing (NLP) and facilitates the creation of chatbots. Anomaly detection is not used for searching and indexing data. This is used to detect outliers in data, such as unusual credit card activity for the detection of fraud.
55.	Transparency provides clarity regarding the purpose of AI solutions, the way they work, as well as their limitations. The privacy and security, reliability and safety, and accountability principles focus on the capabilities of AI, rather than raising awareness about its limitations.
56.	The inclusiveness principle is meant to ensure that AI solutions empower and engage everyone, regardless of criteria such as physical ability, gender, sexual orientation, or ethnicity. Privacy and security, reliability and safety, and accountability do not discriminate based on these criteria, but also do not emphasize the significance of bringing benefits to all parts of the society.
57.	Fairness involves evaluating and mitigating the bias introduced by the features of a model. Privacy is meant to ensure that privacy provisions are included in AI solutions. Transparency provides clarity regarding the purpose of AI solutions, the way they work, as well as their limitations. Accountability is focused on ensuring that AI solutions meet ethical and legal standards that are clearly defined.
58.	Fairness is meant to ensure that AI models do not unintentionally incorporate a bias based on criteria such as gender or ethnicity. Transparency does not apply in this case since banks commonly use their proprietary models when processing loan approvals. Inclusiveness is also out of scope since not everyone is qualified for a loan. Safety is not a primary consideration since there is no direct threat to human life or health in this case.
59.	The accountability principle ensures that AI systems are designed to meet any ethical and legal standards that are applicable. The privacy and security principle states that AI systems must be designed to protect any personal and/or sensitive data. The inclusiveness principle states that AI systems must empower people in a positive and engaging way. The fairness principle is applied to AI system to ensure that users of the systems are treated fairly.
60.	The accountability principle ensures that AI systems are designed to meet any ethical and legal standards that are applicable. The privacy and security principle states that AI systems must be designed to protect any personal and/or sensitive data. The inclusiveness principle states that AI systems must empower people in a positive and engaging way. The fairness principle is applied to AI system to ensure that users of the systems are treated fairly.
61.	NaN, or not a number, designates an unknown confidence score. Unknown is a value with which the NaN confidence score is associated. The score values range between 0 and 1, with 0 designating the lowest confidence score and 1 designating the highest confidence score.
62.	Key phrase extraction is used to extract key phrases to identify the main concepts in a text. It enables a company to identify the main talking points from the support question data and allows them to identify common issues. Named entity recognition can identify and categorize entities in unstructured text, such as people, places, organizations, and quantities. The Speech service, Conversational Language Understanding, and Azure Bot Service are not designed for identifying key phrases or entities.
63.	Key phrase extraction is used to extract key phrases to identify the main concepts in a text. It enables a company to identify the main talking points from the support question data and allows them to identify common issues. Named entity recognition can identify and categorize entities in unstructured text, such as people, places, organizations, and quantities. The Speech service, Conversational Language Understanding, and Azure Bot Service are not designed for identifying key phrases or entities.
64.	Language Name, ISO 6391 Code, and Score are three values returned by the Language service of natural language processing (NLP) in Azure. Bounding box coordinates are returned by the computer vision services in Azure. Wikipedia URL is one of potential values returned by entity linking of entity recognition.
65.	The Universal Language Model used by the speech-to-text API is optimized for conversational and dictation scenarios. The acoustic, language, and pronunciation scenarios require developing your own model.
66.	Model training with a dictionary can be used with Custom Translator when you do not have enough parallel sentences to meet the 10,000 minimum requirements. The resulting model will typically complete training much faster than with full training and will use the baseline models for translation along with the dictionaries you have added.
67.	The two main components of a conversational AI solution are a bot service and a knowledge base. Entity Linking is part of the entity recognition service, which returns links to external websites to disambiguate terms (entities) identified in a text. Key phrase extraction evaluates the text of a document and identifies its main talking points, but it is not one of two main components of a conversational AI solution


































































