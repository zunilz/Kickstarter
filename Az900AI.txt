ML
  -ability to develop algorithm by itself
  -Unsupervised learning and Supervised learning

ML Model
  -is a program that can be used to recognize a pattern in data
  -can be used to predict fututre behaviours
  -can be used to categorize things
  -can be used to recognize people, objects and landmarks
  -can be used to understands speech and text model
  -you train a model
  -you evaluate a model using test data to measure how accurate is it
  -at the end deploy the model

AI Workloads
  -1. Prediction and Demand Forecasting
  -2. Anamoly Detection
  -3. Computer Vision
  -4. NLP
  -5. Conversational AI
  
Guiding Principles of AI
  -Fairness
  -Reliability and Safety
  -Privacy and Security
  -Inclusiveness
  -Transparency
  -Accountability

Machine Learning on Azure
  -Algorithms
    -Regression - finding the relationship between variables
  -Classification
    -Binary classification
    -Multi-class classification
  -Clustering
    -type of unsupervised learning
    -finds groups of related things among data
  -Feature and Labels
    -Feature is an input variable
    -When we are looking to predict a filed, it is called label
  -Training the Model
    -Split the training and validation datasets randomnly
  -Evaluate results - Regression
    -use the validation dataset to test the model
    -Mean Square Error
      -large differences are much worse than small differences
  -Evaluate results - Classification
    -result is to give a prediction score that subject is pasrt of the group
    -False Positives vs False Negatives

  Confusion Matrix
    -Classification Model
      -Actual Values and Predicted values
      -TP, FP, FN, TN
      -          Positive   Negative
       Positive    TP          FP
       Negative    FN          TN
      -Reciever Operating Characteristic (ROC) Curve
      -Area under the Curve (AUC)

No Code ML
  -AutoML is a tool for this
    -Drag dataset onto designer
    -Visualize data, Exclude cloumns if not required
    -Clean rows with missing data
    -Drag training models onto the canvas
    -Once training model as all verified,Training pipeline can be converted into inference pipeline
  -Azure ML designer
    -need to pick the data model unlike auto ML

Computer Vision Workloads
  -Common types of computer vision
    -image classification
    -object detection
    -OCR
    -facial detection and recognition
  -Computer Vision service
    -Azure face service
    -Form recognizer service
  -Custom vision service

NLP
  -Usecases
  -Sentiment analysis
    -positive, negative and neutral
  -Language modelling
  -Speech recognition and synthesis
  -Translation
  -Text Analytics Service
  -Text translation Service
  
Conversational AI
  -QnA maker service
    -to build chatbot
  -Azure Bot Service

Test content:

When categorizing an image, the computer vision service supports two specialized domain models: celebrities and landmarks. Image types is an additional capability of the computer vision service, allowing it to detect the type of image, such as a clip art image or a line drawing. Both people_ and people_group are supported categories when performing image classification.

OCR can extract printed or handwritten text from images. In this case, it can be used to extract text from scanned medical records to produce a digital archive from paper-based documents. 
Identifying wildlife in an image is an example of a computer vision solution that uses object detection and is not suitable for OCR. 
Identifying a user requesting access to a laptop is done by taking images from the laptop’s webcam and using facial detection and recognition to identify the user requesting access. 
Translating speech to text is an example of using speech translation and uses the Speech service as part of Azure Cognitive Services.

Object detection can be used to track livestock animals, such as cows, to support their safety and welfare. For example, a farmer can track whether a particular animal has not been mobile. 
Sentiment analysis is used to return a numeric value based on the analysis of a text. 
Employee access to a secure building can be achieved by using facial recognition. 
Extracting text from manuscripts is an example of a computer vision solution that uses optical character recognition (OCR).
Image classification is part of computer vision and can be used to evaluate images from an X-ray machine to quickly classify specific bone fracture types. This helps improve diagnosis and treatment plans. An image classification model is trained to facilitate the categorizing of the bone fractures. 
Object detection is used to return identified objects in an image, such as a cat, person, or chair. 
Conversational AI is used to create intelligent bots that can interact with people by using natural language. 
Facial detection is used to detect the location of human faces in an image.
The computer vision service eliminates the need for choosing, training, and evaluating a model by providing pre-trained models. To use computer vision, you must create an Azure resource. The use of computer vision involves inferencing.
Detecting objects identifies common objects and, for each, returns bounding box coordinates. Image categorization assigns a category to an image, but it does not return bounding box coordinates. Tagging involves associating an image with metadata that summarizes the attributes of the image, but it does not return bounding box coordinates. OCR detects printed and handwritten text in images, but it does not return bounding box coordinates.

The invoice model extracts key information from sales invoices and is suitable for extracting information from sales account documents. 
The ID document model is optimized to analyze and extract key information from US driver’s licenses and international passport biographical pages. 
The business card model, receipt model, and language model are not suitable to extract information from passports or sales account documents.
Face attributes are a set of features that can be detected by the Face Detect API. Attributes such as accessories (glasses, mask, headwear etc.) can be detected. 
Face rectangle, face ID, and face landmarks do not allow you to determine whether a person is wearing glasses or headwear.
Face identification in the Face service can address one-to-many matching of one face in an image to a set of faces in a secure repository. Face verification has the capability for one-to-one matching of a face in an image to a single face from a secure repository or a photo to verify whether they are the same individual. Face attributes, the find similar faces operation, and Custom Vision do not verify the identity of a face.
Multiple linear regression models a relationship between two or more features and a single label, which matches the scenario in this item. 
Linear regression uses a single feature. Logistic regression is a type of classification model, which returns either a Boolean value or a categorical decision. 
Hierarchical clustering groups data points that have similar characteristics.
Predicting rainfall is an example of regression machine learning, as it will predict a numeric value for future rainfall by using historical time-series rainfall data based on factors, such as seasons. 
Clustering is a machine learning type that analyzes unlabeled data to find similarities in the data. 
Featurization is not a machine learning type, but a collection of techniques, such as feature engineering, data-scaling, and normalization. 
Classification is used to predict categories of data.

Classification is used to predict categories of data. It can predict which category or class an item of data belongs to. In this example, a machine learning model trained by using classification with labeled data can be used to determine the type of bone fracture in a new scan that is not labeled already. Featurization is not a machine learning type. 
Regression is used to predict numeric values. 
Clustering analyzes unlabeled data to find similarities in the data.

In a regression machine learning algorithm, features are used to generate predictions for the label, which is compared to the actual label value. There is no direct comparison of features or labels between the validation and training datasets.
Multiple linear regression models the relationship between several features and a single label. The features must be independent of each other, otherwise, the model's predictions will be misleading.
In a regression machine learning algorithm, a validation set contains known feature and label values.
The price of the house is the label you are attempting to predict through the machine learning model. This is typically done by using a regression model. Floor space size, number of bedrooms, and age of the house are all input variables for the model to help predict the house price label.

Weather temperature and weekday or weekend are features that provide a weather temperature for a given day and a value based on whether the day is on a weekend or weekday. These are input variables for the model to help predict the labels for e-scooter battery levels, number of hires, and distance traveled. E-scooter battery levels, number of hires, and distance traveled are numeric labels you are attempting to predict through the machine learning model.
Splitting data into training and validation datasets leaves you with two datasets, the first and largest of which is the training dataset you use to train the model. The second, smaller dataset is the held back data and is called the validation dataset, as it is used to evaluate the trained model. If normalizing or summarizing the data is required, it will be carried out as part of data transformation. Cleaning missing data is part of preparing the data and the data transformation processes.
A dataset is required to create an automated machine learning (automated ML) run. A workspace must be created before you can access Machine Learning studio. An Azure container instance and an AKS cluster can be created as a deployment target, after training of a model is complete.
Before you can start training a machine learning model, you must first create a pipeline in the Machine Learning designer. This is followed by adding a dataset, adding training modules, and eventually deploying a service.
Time-series forecasting, regression, and classification are supervised machine learning models. Automated ML learning can predict categories or classes by using a classification algorithm, as well as numeric values as part of the regression algorithm, and at a future point in time by using time-series data. Inference pipeline is not a machine learning model. Clustering is unsupervised machine learning and automated ML only works with supervised learning algorithms.
Normalize Data is a data transformation module that is used to change the values of numeric columns in a dataset to a common scale, without distorting differences in the range of values. The Clean Missing Data module is part of preparing the data and data transformation process. Select Columns in Dataset is a data transformation component that is used to choose a subset of columns of interest from a dataset. The train clustering model is not a part of data transformation. The evaluate model is a component used to measure the accuracy of training models.
Linear regression is a machine learning algorithm module used for training regression models. The Clean Missing Data module is part of preparing the data and data transformation process. Select Columns in Dataset is a data transformation component that is used to choose a subset of columns of interest from a dataset. Evaluate model is a component used to measure the accuracy of trained models.
Vectorization captures semantic relationships between words by assigning them to locations in n-dimensional space. Lemmatization, also known as stemming, normalizes words before counting them. Frequency analysis counts how often a word appears in a text. N-grams extend frequency analysis to include multi-term phrases.
Removing stop words is the first step in the statistical analysis of terms used in a text in the context of NLP. Counting the occurrences of each word takes place after stop words are removed. Creating a vectorized model is not part of statistical analysis. It is used to capture the sematic relationship between words. Encoding words as numeric features is not part of statistical analysis. It is frequently used in sentiment analysis.
Sentiment analysis provides sentiment labels, such as negative, neutral, and positive, based on a confidence score from text analysis. This makes it suitable for understanding user sentiment for product reviews. The named entity recognition, key phrase extraction, and language detection features cannot perform sentiment analysis for product reviews.
Key phrase extraction is used to extract key phrases to identify the main concepts in a text. It enables a company to identify the main talking points from the support question data and allows them to identify common issues. Named entity recognition can identify and categorize entities in unstructured text, such as people, places, organizations, and quantities. The Speech service, Conversational Language Understanding, and Azure Bot Service are not designed for identifying key phrases or entities.
Language Name, ISO 6391 Code, and Score are three values returned by the Language service of natural language processing (NLP) in Azure. Bounding box coordinates are returned by the computer vision services in Azure. Wikipedia URL is one of potential values returned by entity linking of entity recognition.
The Universal Language Model used by the speech-to-text API is optimized for conversational and dictation scenarios. The acoustic, language, and pronunciation scenarios require developing your own model.
Azure Cognitive Services provides direct access to both Translator and Speech services through a single endpoint and authentication key. Language service can be used to access the Language service, but not the Translator and Speech services. The Machine Learning service is used to design, implement, and deploy Machine Learning models. Azure Bot Service provides a framework for developing, publishing, and managing bots in Azure.
Entity Linking, PII detection, and sentiment analysis are all elements of the Azure Cognitive Service for Language. Anomaly detection monitors data over time to detect anomalies by using machine learning. Content Moderator is an Azure Cognitive Services service that is used to check text, image, and video content for material that is potentially offensive.
Language identification, speaker recognition, and voice assistants are all elements of the Speech service. Text translation and document translation are part of the Translator service.
Entity Linking identifies and disambiguates the identity of entities found in a text. Key phrase extraction is not used to extract entities and is used instead to extract key phrases to identify the main concepts in a text. Named entity recognition cannot provide a link for each entity to view further information. Text translation is part of the Translator service.
Speech recognition uses audio data to analyze speech and determine recognizable patterns that can be mapped to distinct user voices. Speech synthesis is concerned with vocalizing data, usually by converting text to speech. Speech translation is concerned with multilanguage translation of speech. Language identification is used to identify languages spoken in audio when compared against a list of supported languages.
The two main components of a conversational AI solution are a bot service and a knowledge base. Entity Linking is part of the entity recognition service, which returns links to external websites to disambiguate terms (entities) identified in a text. Key phrase extraction evaluates the text of a document and identifies its main talking points, but it is not one of two main components of a conversational AI solution.




























































